Title: Artificial intelligence art - Wikipedia
URL: https://en.wikipedia.org/wiki/Artificial_intelligence_art
Scraped at: 2025-05-06 13:42:32

Artificial intelligence art Contents History Tools and processes Impact Analysis of existing art using AI Other forms of art See also References Early history Artistic history Technical history Imagery Prompt engineering and sharing Bias Copyright Deception Income and employment stability Power usage Artificial intelligence artisvisual artworkcreated or enhanced through the use ofartificial intelligenceAI programs. Artists began to create artificial intelligence art in the mid to late 20th century when the discipline was founded. Throughoutits history, artificial intelligence art has raised manyphilosophicalconcerns related to thehuman mind, artificial beings, and what can be considered art in a humanAI collaboration. Since the 20th century, artists have used AI to create art, some of which has been exhibited in museums and won awards.1 During theAI boomof the 2020s,text-to-image modelssuch asMidjourney,DALL-E,Stable Diffusion, andFLUX.1became widely available to the public, allowing users to quickly generate imagery with little effort.23Commentary about AI art in the 2020s has often focused on issues related tocopyright,deception,defamation, and its impact on more traditional artists, includingtechnological unemployment. Audience reception shows bias against AI-generated art, where people tend to value artworks less when they know they were created with AI.4Opinions have also risen on the possible effect AI generated art might have on creativity. Automated art dates back at least to theautomataofancient Greek civilization, when inventors such asDaedalusandHero of Alexandriawere described as designing machines capable of writing text, generating sounds, and playing music.56Creative automatons have flourished throughout history, such asMaillardet's automaton, created around 1800 and capable of creating multiple drawings and poems.7 Also in the 19th century,Ada Lovelace, writes that "computing operations" could be used to generate music and poems, now referred to as "The Lovelace Effect," where a computer's behavior is viewed as creative.8Lovelace also discusses a concept known as "The Lovelace Objection," where she argues that a machine has "no pretensions whatever to originate anything."9 In 1950, with the publication ofAlan Turing's paper "Computing Machinery and Intelligence", there was a shift from defining machine intelligence in abstract terms to evaluating whether a machine can mimic human behavior and responses convincingly.10Shortly after, the academic discipline of artificial intelligence was founded at a researchworkshopatDartmouth Collegein 1956.11Since its founding, researchers in the field have explored philosophical questions about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored bymyth,fiction, andphilosophysince antiquity.12 Since the founding of AI in the 1950s, artists have used artificial intelligence to create artistic works. These works were sometimes referred to asalgorithmic art,13computer art,digital art, ornew media art.14 One of the first significant AI art systems isAARON, developed byHarold Cohenbeginning in the late 1960s at theUniversity of Californiaat San Diego.15AARON uses a symbolic rule-based approach to generate technical images in the era ofGOFAIprogramming, and it was developed by Cohen with the goal of being able to code the act of drawing.16AARON was exhibited in 1972 at theLos Angeles County Museum of Art.17From 1973 to 1975, Cohen refined AARON during a residency at theArtificial Intelligence LaboratoryatStanford University.18In 2024, theWhitney Museum of American Artexhibited AI art from throughout Cohen's career, including re-created versions of his early robotic drawing machines.18 Karl Simshas exhibited art created withartificial lifesince the 1980s. He received an M.S. in computer graphics from theMIT Media Labin 1987 and was artist-in-residence from 1990 to 1996 at thesupercomputermanufacturer and artificial intelligence companyThinking Machines.192021In both 1991 and 1992, Sims won the Golden Nica award atPrix Ars Electronicafor his videos using artificial evolution.222324In 1997, Sims created the interactive artificial evolution installationGalápagosfor theNTT InterCommunication Centerin Tokyo.25Sims received anEmmy Awardin 2019 for outstanding achievement in engineering development.26 In 1999,Scott Dravesand a team of several engineers created and releasedElectric Sheepas afree softwarescreensaver.27Electric Sheepis a volunteer computing project for animating and evolvingfractal flames, which are distributed to networked computers which display them as a screensaver. The screensaver used AI to create an infinite animation by learning from its audience. In 2001, Draves won the Fundacion Telefónica Life 4.0 prize forElectric Sheep.28unreliable source? In 2014,Stephanie Dinkinsbegan working onConversations with Bina48.29For the series, Dinkins recorded her conversations withBINA48, a social robot that resembles a middle-aged black woman.3031In 2019, Dinkins won theCreative Capitalaward for her creation of an evolving artificial intelligence based on the "interests and cultures of people of color."32 In 2015,Sougwen ChungbeganMimicry Drawing Operations Unit: Generation 1, an ongoing collaboration between the artist and a robotic arm.33In 2019, Chung won theLumen Prizefor her continued performances with a robotic arm that uses AI to attempt to draw in a manner similar to Chung.34 In 2018, an auction sale of artificial intelligence art was held atChristie'sin New York where the AI artworkEdmond de Belamysold forUS432,500, which was almost 45 times higher than its estimate of US7,00010,000. The artwork was created by Obvious, a Paris-based collective.353637 In 2024, Japanese filmgenerAIdoscopewas released. The film was co-directed byHirotaka Adachi, Takeshi Sone, and Hiroki Yamaguchi. All video, audio, and music in the film were created with artificial intelligence.38 In 2025, Japaneseanimetelevision seriesTwins Hinahimawas released. The anime was produced and animated with AI assistance during the process of cutting and conversion of photographs into anime illustrations and later retouched by art staff. Most of the remaining parts such as characters and logos were hand-drawn with various software.3940 Deep learning, characterized by its multi-layer structure that attempts to mimic the human brain, first came about in the 2010s and causing a significant shift in the world of AI art.41During the deep learning era, there are mainly these types of designs for generative art:autoregressive models,diffusion models,GANs,normalizing flows. In 2014,Ian Goodfellowand colleagues atUniversité de Montréaldeveloped thegenerative adversarial networkGAN, a type ofdeep neural networkcapable of learning to mimic thestatistical distributionof input data such as images. The GAN uses a "generator" to create new images and a "discriminator" to decide which created images are considered successful.42Unlike previous algorithmic art that followed hand-coded rules, generative adversarial networks could learn a specificaestheticby analyzing adatasetof example images.13 In 2015, a team atGooglereleasedDeepDream, a program that uses aconvolutional neural networkto find and enhance patterns in images via algorithmicpareidolia.434445The process creates deliberately over-processed images with a dream-like appearance reminiscent of apsychedelic experience.46Later, in 2017, a conditional GAN learned to generate 1000 image classes ofImageNet, a large visualdatabasedesigned for use invisual object recognition softwareresearch.4748By conditioning the GAN on both random noise and a specific class label, this approach enhanced the quality of image synthesis for class-conditional models.49 Autoregressive modelswere used for image generation, such as PixelRNN 2016, which autoregressively generates one pixel after another with arecurrent neural network.50Immediately after theTransformerarchitecture was proposed inAttention Is All You Need2018, it was used for autoregressive generation of images, but without text conditioning.51 The websiteArtbreeder, launched in 2018, uses the modelsStyleGANand BigGAN5253to allow users to generate and modify images such as faces, landscapes, and paintings.54 In the 2020s,text-to-image models, which generate images based onprompts, became widely used, marking yet another shift in the creation of AI generated artworks.2 In 2021, using the influentiallarge languagegenerative pre-trained transformermodels that are used inGPT-2andGPT-3,OpenAIreleased a series of images created with the text-to-image AI modelDALL-E 1.55It was an autoregressive generative model with essentially the same architecture as GPT-3. Along with this, later in 2021,EleutherAIreleased theopen sourceVQGAN-CLIP56based on OpenAI's CLIP model.57Diffusion models, generative models used to create synthetic data based on existing data,58were first proposed in 2015,59but they only became better than GANs in early 2021.60Latent diffusion modelwas published in December 2021 and became the basis for the laterStable DiffusionAugust 2022.61 In 2022,Midjourney62was released, followed byGoogle Brain'sImagenand Parti, which were announced in May 2022,Microsoft's NUWA-Infinity,632and thesource-availableStable Diffusion, which was released in August 2022.646566DALL-E2, a successor to DALL-E, was beta-tested and released with the further successor DALL-E3 being released in 2023. Stability AI has a Stable Diffusion web interface called DreamStudio,67plugins forKrita,Photoshop,Blender, andGIMP,68and theAutomatic1111web-based open sourceuser interface.697071Stable Diffusion's main pre-trained model is shared on theHugging Face Hub.72 Ideogramwas released in August 2023, this model is known for its ability to generate legible text.7374 In 2024,Fluxwas released. This model can generate realistic images and was integrated intoGrok, the chatbot used onX formerly Twitter, andLe Chat, the chatbot ofMistral AI.3757677Flux was developed by Black Forest Labs, founded by the researchers behind Stable Diffusion.78Grok later switched to its own text-to-image modelAurorain December of the same year.79Several companies, along with their products, have also developed an AI model integrated with an image editing service.Adobehas released and integrated the AI modelFireflyintoPremiere Pro,Photoshop, andIllustrator.8081Microsoft has also publicly announced AI image-generator features forMicrosoft Paint.82Along with this, some examples oftext-to-video modelsof the mid-2020s areRunway's Gen-2, Google'sVideoPoet, and OpenAI'sSora, which was released in December 2024.8384 There are many tools available to the artist when working with diffusion models. They can define both positive and negative prompts, but they are also afforded a choice in using or omitting the use ofVAEs,LoRAs, hypernetworks, IP-adapter, and embeddingtextual inversions. Artists can tweak settings like guidance scale which balances creativity and accuracy, seed to control randomness, and upscalers to enhance image resolution, among others. Additional influence can be exerted during pre-inference by means of noise manipulation, while traditional post-processing techniques are frequently used post-inference. People can also train their own models. In addition, procedural "rule-based" generation of images using mathematical patterns, algorithms that simulate brush strokes and other painted effects, and deep learning algorithms such as generative adversarial networks GANs and transformers have been developed. Several companies have released apps and websites that allow one to forego all the options mentioned entirely while solely focusing on the positive prompt. There also exist programs which transform photos into art-like images in the style of well-known sets of paintings.8586 There are many options, ranging from simple consumer-facing mobile apps toJupyternotebooks and web UIs that require powerful GPUs to run effectively.87Additional functionalities include "textual inversion," which refers to enabling the use of user-provided concepts like an object or a style learned from a few images. Novel art can then be generated from the associated words the text that has been assigned to the learned, often abstract, concept8889and model extensions or fine-tuning such asDreamBooth. AI has the potential for asocietal transformation, which may include enabling the expansion of noncommercial niche genres such ascyberpunk derivativeslikesolarpunk by amateurs, novel entertainment, fast prototyping,90increasing art-making accessibility,90and artistic output per effort or expenses or time90e.g., via generating drafts, draft-definitions, and image components inpainting. Generated images are sometimes used as sketches,91low-cost experiments,92inspiration, or illustrations ofproof-of-concept-stage ideas. Additional functionalities or improvements may also relate to post-generation manual editing i.e., polishing, such as subsequent tweaking with an image editor.92 Promptsfor some text-to-image models can also include images and keywords and configurable parameters, such as artistic style, which is often used via keyphrases like "in the style of name of an artist" in the prompt93or selection of a broad aestheticart style.9491There are platforms for sharing, trading, searching, forkingrefining, or collaborating on prompts for generating specific imagery from image generators.95969798Prompts are often shared along with images onimage-sharingwebsites such asRedditand AI art-dedicated websites. A prompt is not the complete input needed for the generation of an image; additional inputs that determine the generated image include theoutput resolution,random seed, and random sampling parameters.99 Synthetic media, which includes AI art, was described in 2022 as a major technology-driven trend that will affect business in the coming years.90Harvard Kennedy Schoolresearchers voiced concerns about synthetic media serving as a vector for political misinformation soon after studying the proliferation of AI art on the X platform.100Synthographyis a proposed term for the practice of generating images that are similar to photographs using AI.101 A major concern raised about AI-generated images and art issampling biaswithin model training data leading towards discriminatory output from AI art models. In 2023,University of Washingtonresearchers found evidence of racial bias within the Stable Diffusion model, with images of a "person" corresponding most frequently with images of males from Europe or North America.102 Looking more into thesampling biasfound within AI training data, in 2017, researchers at Princeton University used AI software to link over 2 million words, finding that European names were viewed as more "pleasant" than African-Americans names, and that the words "woman" and "girl" were more likely to be associated with the arts instead of science and math, "which were most likely connected to males."103Generative AI models typically work based on user-entered word-based prompts, especially in the case ofdiffusion models, and this word-related bias may lead to biased results. Along with this, generative AI can perpetuate harmful stereotypes regarding women. For example,Lensa, an AI app that trended onTikTokin 2023, was known to lighten black skin, make users thinner, and generate hypersexualized images of women.104Melissa Heikkilä, a senior reporter atMIT Technology Review, shared the findings of an experiment using Lensa, noting that the generated avatars did not resemble her and often depicted her in a hypersexualized manner.105Experts suggest that such outcomes can result from biases in the datasets used to train AI models, which can sometimes contain imbalanced representations, including hypersexual or nude imagery.106107 In 2024, Google'schatbotGemini's AI image generator was criticized for perceivedracial bias, with claims that Gemini deliberately underrepresented white people in its results.108Users reported that it generated images of white historical figures like theFounding Fathers,Nazi soldiers, andVikingsas other races, and that it refused to process prompts such as "happy white people" and "idealnuclear family".108109Google later apologized for "missing the mark" and took Gemini's image generator offline for updates.110This prompted discussions about the ethical implications111of representing historical figures through a contemporary lens, leading critics to argue that these outputs could mislead audiences regarding actual historical contexts.112In addition to the well-documented representational issues such as racial and gender bias, some scholars have also pointed out deeper conceptual assumptions that shape how we perceive AI-generated art. For instance, framing AI strictly as a passive tool overlooks how cultural and technological factors influence its outputs. Others suggest viewing AI as part of a collaborative creative process, where both human and machine contribute to the artistic result.113 Legal scholars, artists, and media corporations have considered the legal and ethical implications of artificial intelligence art since the 20th century. Some artists use AI art to critique and explore the ethics of usinggathered datato produce new artwork.114 In 1985, intellectual property law professorPamela Samuelsonargued thatUS copyrightshould allocate algorithmically generated artworks to the user of the computer program.115A 2019Florida Law Reviewarticle presented three perspectives on the issue. In the first, artificial intelligence itself would become the copyright owner; to do this, Section 101 of the US Copyright Act would need to be amended to define "author" as a computer. In the second, following Samuelson's argument, the user, programmer, or artificial intelligence company would be the copyright owner. This would be an expansion of the "work for hire" doctrine, under which ownership of a copyright is transferred to the "employer." In the third situation, copyright assignments would never take place, and such works would be in thepublic domain, as copyright assignments require an act of authorship.116 In 2022, coinciding with the rising availability of consumer-grade AI image generation services, popular discussion renewed over the legality and ethics of AI-generated art. A particular topic is the inclusion of copyrighted artwork and images in AI training datasets, with artists objecting to commercial AI products using their works without consent, credit, or financial compensation.117In September 2022, Reema Selhi, of theDesign and Artists Copyright Society, stated that "there are no safeguards for artists to be able to identify works in databases that are being used and opt out."118Some have claimed that images generated with these models can bear resemblance to extant artwork, sometimes including the remains of the original artist's signature.118119In December 2022, users of the portfolio platform ArtStation staged an online protest against non-consensual use of their artwork within datasets; this resulted in opt-out services, such as "Have I Been Trained?" increasing in profile, as well as some online art platforms promising to offer their own opt-out options.120According to theUS Copyright Office, artificial intelligence programs are unable to hold copyright,121122123a decision upheld at the Federal District level as of August 2023 followed the reasoning from themonkey selfie copyright dispute.124 OpenAI, the developer ofDALL-E, has its own policy on who owns generated art. They assign the right and title of a generated image to the creator, meaning the user who inputted the prompt owns the image generated, along with the right to sell, reprint, and merchandise it.125 In January 2023, three artistsSarah Andersen,Kelly McKernan, and Karla Ortizfiled acopyright infringementlawsuit against Stability AI,Midjourney, andDeviantArt, claiming that it is legally required to obtain the consent of artists before training neural nets on their work and that these companies infringed on the rights of millions of artists by doing so on five billion images scraped from the web.126In July 2023, U.S. District JudgeWilliam Orrickwas inclined to dismiss most of the lawsuits filed by Andersen, McKernan, and Ortiz, but allowed them to file a new complaint.127Also in 2023, Stability AI was sued byGetty Imagesfor using its images in the training data.128A tool built bySimon Willisonallowed people to search 0.5 of the training data for Stable Diffusion V1.1, i.e., 12 million of the 2.3 billion instances fromLAION2B. Artist Karen Hallion discovered that her copyrighted images were used as training data without their consent.129 In March 2024, Tennessee enacted theELVIS Act, which prohibits the use of AI to mimic a musician's voice without permission.130A month later in that year,Adam Schiffintroduced theGenerative AI Copyright Disclosure Actwhich, if passed, would require that AI companies to submit copyrighted works in their datasets to theRegister of Copyrightsbefore releasing new generative AI systems.131In November 2024, a group of artists and activists shared early access to OpenAIs unreleased video generation model,Sora, viaHuggingface. The action, accompanied by a statement, criticized the exploitative use of artists work by major corporations.'132133134 As with other types ofphoto manipulationsince the early 19th century, some people in the early 21st century have been concerned that AI could be used to create content that is misleading and can be made to damage a person's reputation, such asdeepfakes.135ArtistSarah Andersen, who previously had her art copied and edited to depictNeo-Nazibeliefs, stated that the spread ofhate speechonline can be worsened by the use of image generators.129Some also generate images or videos for the purpose ofcatfishing. AI systems have the ability to create deepfake content, which is often viewed as harmful and offensive. The creation of deepfakes poses a risk to individuals who have not consented to it.136This mainly refers todeepfake pornographywhich is used asrevenge porn, where sexually explicit material is disseminated to humiliate or harm another person. AI-generatedchild pornographyhas been deemed a potential danger to society due to its unlawful nature.137 After winning the 2023 "Creative" "Open competition" Sony World Photography Awards, Boris Eldagsen stated that his entry was actually created with artificial intelligence. Photographer Feroz Khan commented to theBBCthat Eldagsen had "clearly shown that even experienced photographers and art experts can be fooled".139Smaller contests have been affected as well; in 2023, a contest run by authorMark LawrenceasSelf-Published Fantasy Blog-Offwas cancelled after the winning entry was allegedly exposed to be a collage of images generated with Midjourney.140 In May 2023, on social media sites such as Reddit and Twitter, attention was given to a Midjourney-generated image ofPope Franciswearing a white puffer coat.141142Additionally, an AI-generated image of an attack on thePentagonwent viral as part of ahoax news storyon Twitter.143144 In the days beforeMarch 2023 indictment of Donald Trumpas part of theStormy DanielsDonald Trump scandal, several AI-generated images allegedly depicting Trump's arrest went viral online.145146On March 20, British journalistEliot Higginsgenerated various images of Donald Trump being arrested or imprisoned using Midjourney v5 and posted them on Twitter; two images of Trump struggling against arresting officers went viral under the mistaken impression that they were genuine, accruing more than 5 million views in three days.147148According to Higgins, the images were not meant to mislead, but he was banned from using Midjourney services as a result. As of April 2024, the tweet had garnered more than 6.8 million views. In February 2024, the paperCellular functions of spermatogonial stem cells in relation to JAKSTAT signaling pathwaywas published using AI-generated images. It was later retracted fromFrontiers in Cell and Developmental Biologybecause the paper "does not meet the standards".149 To mitigate some deceptions, OpenAI developed a tool in 2024 to detect images that were generated by DALL-E 3.150In testing, this tool accurately identified DALL-E 3-generated images approximately 98 of the time. The tool is also fairly capable of recognizing images that have been visually modified by users post-generation.151 As generative AI image software such asStable DiffusionandDALL-Econtinue to advance, the potential problems and concerns that these systems pose for creativity and artistry have risen.129In 2022, artists working in various media raised concerns about the impact thatgenerative artificial intelligencecould have on their ability to earn money, particularly if AI-based images started replacing artists working in theillustration and design industries.152153In August 2022, digital artist R. J. Palmer stated that "I could easily envision a scenario where using AI, a single artist or art director could take the place of 510 entry level artists... I have seen a lot of self-published authors and such say how great it will be that they dont have to hire an artist."119Scholars Jiang et al. state that "Leaders of companies like Open AI and Stability AI have openly stated that they expect generative AI systems to replace creatives imminently."129A 2022 case study found that AI-produced images created by technology likeDALL-Ecaused some traditional artists to be concerned about losing work, while others use it to their advantage and view it as a tool.136 AI-based images have become more commonplace in art markets and search engines because AI-basedtext-to-image systemsare trained from pre-existing artistic images, sometimes without the original artist's consent, allowing the software to mimic specific artists' styles.129154For example, Polish digital artist Greg Rutkowski has stated that it is more difficult to search for his work online because many of the images in the results are AI-generated specifically to mimic his style.65Furthermore, some training databases on which AI systems are based are not accessible to the public. The ability of AI-based art software to mimic or forge artistic style also raises concerns of malice or greed.129155156Works of AI-generated art, such asThéâtre D'opéra Spatial, a text-to-image AI illustration that won the grand prize in the August 2022 digital art competition at theColorado State Fair, have begun to overwhelm art contests and other submission forums meant for small artists.129155156TheNetflixshort filmThe Dog  the Boy, released in January 2023, received backlash online for its use of artificial intelligence art to create the film's background artwork.157Within the same vein,DisneyreleasedSecret Invasion, aMarvelTV show with an AI-generated intro, on Disney in 2023, causing concern and backlash regarding the idea that artists could be made obsolete by machine-learning tools.158 AI art has sometimes been deemed to be able to replace traditionalstock images.159In 2023,Shutterstockannounced a beta test of an AI tool that can regenerate partial content of other Shutterstock's images.Getty ImagesandNvidiahave partnered with the launch of Generative AI byiStock, a model trained on Getty's library and iStock's photo library using Nvidia's Picasso model.160 Researchers fromHugging FaceandCarnegie Mellon Universityreported in a 2023 paper that generating one thousand 10241024 images usingStable Diffusion's XL 1.0 base model requires 11.49kWhof energy and generates 1,594 grams 56.2 oz ofcarbon dioxide, which is roughly equivalent to driving an average gas-powered car a distance of 4.1 miles 6.6 km. Comparing 88 different models, the paper concluded that image-generation models used on average around 2.9kWh of energy per 1,000inferences.161 In addition to the creation of original art, research methods that use AI have been generated to quantitatively analyze digital art collections. This has been made possible due to the large-scale digitization of artwork in the past few decades. According to CETINIC and SHE 2022, using artificial intelligence to analyze already-existing art collections can provide new perspectives on the development of artistic styles and the identification of artistic influences.162163 Two computational methods, close reading and distant viewing, are the typical approaches used to analyze digitized art.164Close reading focuses on specific visual aspects of one piece. Some tasks performed by machines in close reading methods include computational artist authentication and analysis of brushstrokes or texture properties. In contrast, through distant viewing methods, the similarity across an entire collection for a specific feature can be statistically visualized. Common tasks relating to this method include automatic classification,object detection,multimodal tasks, knowledge discovery in art history, and computational aesthetics.163Synthetic images can also be used to train AI algorithms forart authenticationand to detect forgeries.165 Researchers have also introduced models that predict emotional responses to art. One such model is ArtEmis, a large-scale dataset paired with machine learning models. ArtEmis includes emotional annotations from over 6,500 participants along with textual explanations. By analyzing both visual inputs and the accompanying text descriptions from this dataset, ArtEmis enables the generation of nuanced emotional predictions.166167 AI has also been used in arts outside of visual arts. Generative AI has been used in video game productionbeyond imagery, especially forlevel designe.g., forcustom maps and creating new content e.g., quests or dialogue orinteractive storiesin video games.168169AI has also been used in theliterary arts,170such as helping withwriter's block, inspiration, or rewriting segments.171172173174In the culinary arts, some prototypecooking robotscan dynamicallytaste, which can assist chefs in analyzing the content and flavor of dishes during the cooking process.175 TITLE: Artificial intelligence art - Wikipedia